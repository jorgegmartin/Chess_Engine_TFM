{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.engine\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10200472492081303375\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6254755840\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11956849656963075820\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:09:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_13176\\3326022288.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.utils as utils\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "\n",
    "\n",
    "def build_model(conv_size, conv_depth):\n",
    "  board3d = layers.Input(shape=(14, 8, 8))\n",
    "\n",
    "  # adding the convolutional layers\n",
    "  x = board3d\n",
    "  for _ in range(conv_depth):\n",
    "    x = layers.Conv2D(filters=conv_size, kernel_size=3, padding='same', activation='relu', data_format='channels_first')(x)\n",
    "  x = layers.Flatten()(x)\n",
    "  x = layers.Dense(64, 'relu')(x)\n",
    "  x = layers.Dense(1, 'sigmoid')(x)\n",
    "\n",
    "  return models.Model(inputs=board3d, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "model = build_model(32, 4)\n",
    "utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip connections (residual network) will likely improve the model for deeper connections. If you want to test the residual model, check the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_residual(conv_size, conv_depth):\n",
    "  board3d = layers.Input(shape=(14, 8, 8))\n",
    "\n",
    "  # adding the convolutional layers\n",
    "  x = layers.Conv2D(filters=conv_size, kernel_size=3, padding='same', data_format='channels_first')(board3d)\n",
    "  for _ in range(conv_depth):\n",
    "    previous = x\n",
    "    x = layers.Conv2D(filters=conv_size, kernel_size=3, padding='same', data_format='channels_first')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(filters=conv_size, kernel_size=3, padding='same', data_format='channels_first')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([x, previous])\n",
    "    x = layers.Activation('relu')(x)\n",
    "  x = layers.Flatten()(x)\n",
    "  x = layers.Dense(1, 'sigmoid')(x)\n",
    "\n",
    "  return models.Model(inputs=board3d, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It's training time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500000, 14, 8, 8)\n",
      "(1500000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.callbacks as callbacks\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "\tcontainer = np.load(r'C:\\Users\\Usuario\\Desktop\\Data Science Projects\\Chess_Engine_TFM\\data\\random_generated\\dataset.npz')\n",
    "\tb, v = container['b'], container['v']\n",
    "\tv = np.asarray(v / abs(v).max() / 2 + 0.5, dtype=np.float32) # normalization (0 - 1)\n",
    "\treturn b, v\n",
    "\n",
    "\n",
    "x_train, y_train = get_dataset()\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 14, 8, 8)]        0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 8, 8)          4064      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 8, 8)          9248      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 8, 8)          9248      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 8, 8)          9248      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                131136    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163,009\n",
      "Trainable params: 163,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.Adam(5e-4), loss='mean_squared_error')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "660/660 [==============================] - 17s 15ms/step - loss: 0.0012 - val_loss: 6.9362e-04 - lr: 5.0000e-04\n",
      "Epoch 2/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 5.7919e-04 - val_loss: 5.4775e-04 - lr: 5.0000e-04\n",
      "Epoch 3/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 4.7209e-04 - val_loss: 5.0296e-04 - lr: 5.0000e-04\n",
      "Epoch 4/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 4.2278e-04 - val_loss: 4.6515e-04 - lr: 5.0000e-04\n",
      "Epoch 5/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 3.9067e-04 - val_loss: 4.1196e-04 - lr: 5.0000e-04\n",
      "Epoch 6/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 3.7008e-04 - val_loss: 4.2994e-04 - lr: 5.0000e-04\n",
      "Epoch 7/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 3.4864e-04 - val_loss: 3.6814e-04 - lr: 5.0000e-04\n",
      "Epoch 8/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 3.3617e-04 - val_loss: 3.4716e-04 - lr: 5.0000e-04\n",
      "Epoch 9/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 3.2012e-04 - val_loss: 3.8013e-04 - lr: 5.0000e-04\n",
      "Epoch 10/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 3.1172e-04 - val_loss: 3.1354e-04 - lr: 5.0000e-04\n",
      "Epoch 11/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 2.9471e-04 - val_loss: 3.1448e-04 - lr: 5.0000e-04\n",
      "Epoch 12/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 2.8913e-04 - val_loss: 3.2778e-04 - lr: 5.0000e-04\n",
      "Epoch 13/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 2.8263e-04 - val_loss: 3.2557e-04 - lr: 5.0000e-04\n",
      "Epoch 14/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 2.7536e-04 - val_loss: 3.2771e-04 - lr: 5.0000e-04\n",
      "Epoch 15/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 2.6599e-04 - val_loss: 2.9880e-04 - lr: 5.0000e-04\n",
      "Epoch 16/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 2.6253e-04 - val_loss: 2.8691e-04 - lr: 5.0000e-04\n",
      "Epoch 17/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 2.5654e-04 - val_loss: 3.0375e-04 - lr: 5.0000e-04\n",
      "Epoch 18/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 2.5027e-04 - val_loss: 3.0358e-04 - lr: 5.0000e-04\n",
      "Epoch 19/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 2.4471e-04 - val_loss: 2.9239e-04 - lr: 5.0000e-04\n",
      "Epoch 20/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 2.3942e-04 - val_loss: 3.1871e-04 - lr: 5.0000e-04\n",
      "Epoch 21/1000\n",
      "660/660 [==============================] - 10s 14ms/step - loss: 2.3479e-04 - val_loss: 2.9385e-04 - lr: 5.0000e-04\n",
      "Epoch 22/1000\n",
      "660/660 [==============================] - 9s 13ms/step - loss: 2.3202e-04 - val_loss: 2.7824e-04 - lr: 5.0000e-04\n",
      "Epoch 23/1000\n",
      "660/660 [==============================] - 9s 13ms/step - loss: 2.2743e-04 - val_loss: 3.1580e-04 - lr: 5.0000e-04\n",
      "Epoch 24/1000\n",
      "660/660 [==============================] - 8s 12ms/step - loss: 2.2067e-04 - val_loss: 3.2873e-04 - lr: 5.0000e-04\n",
      "Epoch 25/1000\n",
      "660/660 [==============================] - 8s 12ms/step - loss: 2.1910e-04 - val_loss: 2.7963e-04 - lr: 5.0000e-04\n",
      "Epoch 26/1000\n",
      "660/660 [==============================] - 8s 11ms/step - loss: 1.9165e-04 - val_loss: 2.7488e-04 - lr: 5.0000e-05\n",
      "Epoch 27/1000\n",
      "660/660 [==============================] - 8s 12ms/step - loss: 1.8955e-04 - val_loss: 2.7389e-04 - lr: 5.0000e-05\n",
      "Epoch 28/1000\n",
      "660/660 [==============================] - 8s 11ms/step - loss: 1.8867e-04 - val_loss: 2.7778e-04 - lr: 5.0000e-05\n",
      "Epoch 29/1000\n",
      "660/660 [==============================] - 7s 11ms/step - loss: 1.8801e-04 - val_loss: 2.7630e-04 - lr: 5.0000e-05\n",
      "Epoch 30/1000\n",
      "660/660 [==============================] - 8s 12ms/step - loss: 1.8717e-04 - val_loss: 2.8308e-04 - lr: 5.0000e-05\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=2048,\n",
    "          epochs=1000,\n",
    "          verbose=1,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='loss', patience=10),\n",
    "                     callbacks.EarlyStopping(monitor='loss', patience=15, min_delta=1e-4)])\n",
    "\n",
    "model.save('./engine_models/basic_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93eda801d5fd29625c3423228d2952e23befdd4fb970236ec85dd514a35765ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
