{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.engine\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7095287981253390407\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6254755840\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11257997813592941337\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:09:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.utils as utils\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "\n",
    "\n",
    "def build_model(conv_size, conv_depth):\n",
    "  board3d = layers.Input(shape=(14, 8, 8))\n",
    "\n",
    "  # adding the convolutional layers\n",
    "  x = board3d\n",
    "  for _ in range(conv_depth):\n",
    "    x = layers.Conv2D(filters=conv_size, kernel_size=3, padding='same', activation='relu', data_format='channels_first')(x)\n",
    "  x = layers.Flatten()(x)\n",
    "  x = layers.Dense(64, 'relu')(x)\n",
    "  x = layers.Dense(1, 'sigmoid')(x)\n",
    "\n",
    "  return models.Model(inputs=board3d, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "model = build_model(32, 4)\n",
    "utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip connections (residual network) will likely improve the model for deeper connections. If you want to test the residual model, check the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_residual(conv_size, conv_depth):\n",
    "  board3d = layers.Input(shape=(14, 8, 8))\n",
    "\n",
    "  # adding the convolutional layers\n",
    "  x = layers.Conv2D(filters=conv_size, kernel_size=3, padding='same', data_format='channels_first')(board3d)\n",
    "  for _ in range(conv_depth):\n",
    "    previous = x\n",
    "    x = layers.Conv2D(filters=conv_size, kernel_size=3, padding='same', data_format='channels_first')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(filters=conv_size, kernel_size=3, padding='same', data_format='channels_first')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([x, previous])\n",
    "    x = layers.Activation('relu')(x)\n",
    "  x = layers.Flatten()(x)\n",
    "  x = layers.Dense(1, 'sigmoid')(x)\n",
    "\n",
    "  return models.Model(inputs=board3d, outputs=x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training ⬇️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500000, 14, 8, 8)\n",
      "(1500000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.callbacks as callbacks\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "\tcontainer = np.load(r'C:\\Users\\Usuario\\Desktop\\Data Science Projects\\Chess_Engine_TFM\\data\\random_generated\\random_boards_d6.npz', allow_pickle=True)\n",
    "\tb, v, f = container['board_matrix'], container['eval'], container['board_fen']\n",
    "\tv[v == None] = 0\n",
    "\tv = np.asarray(v / abs(v).max() / 2 + 0.5, dtype=np.float32) # normalization (0 - 1)\n",
    "\treturn b, v\n",
    "\n",
    "\n",
    "x_train, y_train = get_dataset()\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 14, 8, 8)]        0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 8, 8)          4064      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 8, 8)          9248      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 8, 8)          9248      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 8, 8)          9248      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                131136    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163,009\n",
      "Trainable params: 163,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.Adam(5e-4), loss='mean_squared_error')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "660/660 [==============================] - 9s 12ms/step - loss: 0.0011 - val_loss: 0.0011 - lr: 5.0000e-04\n",
      "Epoch 2/1000\n",
      "660/660 [==============================] - 8s 12ms/step - loss: 0.0011 - val_loss: 0.0011 - lr: 5.0000e-04\n",
      "Epoch 3/1000\n",
      "660/660 [==============================] - 8s 12ms/step - loss: 0.0011 - val_loss: 0.0011 - lr: 5.0000e-04\n",
      "Epoch 4/1000\n",
      "660/660 [==============================] - 8s 12ms/step - loss: 0.0011 - val_loss: 0.0012 - lr: 5.0000e-04\n",
      "Epoch 5/1000\n",
      "660/660 [==============================] - 8s 12ms/step - loss: 0.0011 - val_loss: 0.0012 - lr: 5.0000e-04\n",
      "Epoch 6/1000\n",
      "660/660 [==============================] - 8s 12ms/step - loss: 0.0011 - val_loss: 0.0011 - lr: 5.0000e-04\n",
      "Epoch 7/1000\n",
      "660/660 [==============================] - 8s 13ms/step - loss: 0.0011 - val_loss: 0.0011 - lr: 5.0000e-04\n",
      "Epoch 8/1000\n",
      "660/660 [==============================] - 8s 12ms/step - loss: 0.0010 - val_loss: 0.0011 - lr: 5.0000e-04\n",
      "Epoch 9/1000\n",
      "660/660 [==============================] - 8s 12ms/step - loss: 0.0010 - val_loss: 0.0011 - lr: 5.0000e-04\n",
      "Epoch 10/1000\n",
      "660/660 [==============================] - 9s 13ms/step - loss: 0.0010 - val_loss: 0.0012 - lr: 5.0000e-04\n",
      "Epoch 11/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 0.0010 - val_loss: 0.0012 - lr: 5.0000e-04\n",
      "Epoch 12/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 9.9462e-04 - val_loss: 0.0012 - lr: 5.0000e-04\n",
      "Epoch 13/1000\n",
      "660/660 [==============================] - 8s 12ms/step - loss: 9.8648e-04 - val_loss: 0.0012 - lr: 5.0000e-04\n",
      "Epoch 14/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 9.7090e-04 - val_loss: 0.0012 - lr: 5.0000e-04\n",
      "Epoch 15/1000\n",
      "660/660 [==============================] - 10s 15ms/step - loss: 9.6442e-04 - val_loss: 0.0012 - lr: 5.0000e-04\n",
      "Epoch 16/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 9.5280e-04 - val_loss: 0.0012 - lr: 5.0000e-04\n",
      "Epoch 17/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 9.4167e-04 - val_loss: 0.0012 - lr: 5.0000e-04\n",
      "Epoch 18/1000\n",
      "660/660 [==============================] - 10s 14ms/step - loss: 9.3178e-04 - val_loss: 0.0012 - lr: 5.0000e-04\n",
      "Epoch 19/1000\n",
      "660/660 [==============================] - 9s 13ms/step - loss: 9.2767e-04 - val_loss: 0.0012 - lr: 5.0000e-04\n",
      "Epoch 20/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 9.1643e-04 - val_loss: 0.0012 - lr: 5.0000e-04\n",
      "Epoch 21/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 9.1102e-04 - val_loss: 0.0012 - lr: 5.0000e-04\n",
      "Epoch 22/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 9.0186e-04 - val_loss: 0.0012 - lr: 5.0000e-04\n",
      "Epoch 23/1000\n",
      "660/660 [==============================] - 9s 14ms/step - loss: 8.9578e-04 - val_loss: 0.0012 - lr: 5.0000e-04\n",
      "Epoch 24/1000\n",
      "660/660 [==============================] - 9s 13ms/step - loss: 8.8893e-04 - val_loss: 0.0012 - lr: 5.0000e-04\n",
      "Epoch 25/1000\n",
      "660/660 [==============================] - 8s 12ms/step - loss: 8.8244e-04 - val_loss: 0.0012 - lr: 5.0000e-04\n",
      "Epoch 26/1000\n",
      "660/660 [==============================] - 9s 13ms/step - loss: 8.7966e-04 - val_loss: 0.0013 - lr: 5.0000e-04\n",
      "Epoch 27/1000\n",
      "660/660 [==============================] - 7s 10ms/step - loss: 8.7099e-04 - val_loss: 0.0013 - lr: 5.0000e-04\n",
      "Epoch 28/1000\n",
      "660/660 [==============================] - 7s 11ms/step - loss: 8.6595e-04 - val_loss: 0.0012 - lr: 5.0000e-04\n",
      "Epoch 29/1000\n",
      "660/660 [==============================] - 7s 10ms/step - loss: 8.2660e-04 - val_loss: 0.0012 - lr: 5.0000e-05\n",
      "Epoch 30/1000\n",
      "660/660 [==============================] - 7s 11ms/step - loss: 8.2017e-04 - val_loss: 0.0012 - lr: 5.0000e-05\n",
      "Epoch 31/1000\n",
      "660/660 [==============================] - 7s 11ms/step - loss: 8.1755e-04 - val_loss: 0.0012 - lr: 5.0000e-05\n",
      "Epoch 32/1000\n",
      "660/660 [==============================] - 8s 12ms/step - loss: 8.1579e-04 - val_loss: 0.0012 - lr: 5.0000e-05\n",
      "Epoch 33/1000\n",
      "660/660 [==============================] - 8s 13ms/step - loss: 8.1388e-04 - val_loss: 0.0012 - lr: 5.0000e-05\n",
      "Epoch 34/1000\n",
      "660/660 [==============================] - 8s 12ms/step - loss: 8.1257e-04 - val_loss: 0.0012 - lr: 5.0000e-05\n",
      "Epoch 35/1000\n",
      "660/660 [==============================] - 8s 13ms/step - loss: 8.1097e-04 - val_loss: 0.0012 - lr: 5.0000e-05\n",
      "Epoch 36/1000\n",
      "660/660 [==============================] - 8s 12ms/step - loss: 8.0958e-04 - val_loss: 0.0012 - lr: 5.0000e-05\n",
      "Epoch 37/1000\n",
      "660/660 [==============================] - 8s 12ms/step - loss: 8.0857e-04 - val_loss: 0.0012 - lr: 5.0000e-05\n",
      "Epoch 38/1000\n",
      "660/660 [==============================] - 8s 13ms/step - loss: 8.0725e-04 - val_loss: 0.0012 - lr: 5.0000e-05\n",
      "Epoch 39/1000\n",
      "660/660 [==============================] - 8s 12ms/step - loss: 8.0594e-04 - val_loss: 0.0012 - lr: 5.0000e-05\n",
      "Epoch 40/1000\n",
      "660/660 [==============================] - 9s 13ms/step - loss: 8.0038e-04 - val_loss: 0.0012 - lr: 5.0000e-06\n",
      "Epoch 41/1000\n",
      "660/660 [==============================] - 8s 12ms/step - loss: 8.0001e-04 - val_loss: 0.0012 - lr: 5.0000e-06\n",
      "Epoch 42/1000\n",
      "660/660 [==============================] - 8s 12ms/step - loss: 7.9985e-04 - val_loss: 0.0012 - lr: 5.0000e-06\n",
      "Epoch 43/1000\n",
      "660/660 [==============================] - 8s 13ms/step - loss: 7.9970e-04 - val_loss: 0.0012 - lr: 5.0000e-06\n",
      "Epoch 44/1000\n",
      "660/660 [==============================] - 8s 12ms/step - loss: 7.9953e-04 - val_loss: 0.0012 - lr: 5.0000e-06\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=2048,\n",
    "          epochs=1000,\n",
    "          verbose=1,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='loss', patience=10),\n",
    "                     callbacks.EarlyStopping(monitor='loss', patience=15, min_delta=1e-4)])\n",
    "\n",
    "model.save('./engine_models/depth6_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 14:38:14) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93eda801d5fd29625c3423228d2952e23befdd4fb970236ec85dd514a35765ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
